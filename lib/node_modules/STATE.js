const localdb = require('localdb')
const io = require('io')

/******************************************************************************
  STATE
******************************************************************************/
let db

const VERSION = 13
const HELPER_MODULES = ['io', 'localdb', 'STATE']
const admins = [0] // Symbol mappings
const status = {
  root_module: true,
  root_instance: true,
  overrides: {},
  tree: {},
  tree_pointers: {},
  modulepaths: {},
  addresses: {},
  inits: [],
//  open_branches: {},
  db,
  local_statuses: {},
  listeners: {},
  missing_supers: new Set(),
  imports: {},
  expected_imports: {},
  used_ids: new Set(),
  a2i: {},
  i2a: {},
  s2i: {},
  i2s: {},
  services: {},
  args: {},
  callbacks: [],
  root_datasets: [],
  dataset_types: {},
}
const {
  FAIL_admin_access,
  FAIL_id,
  FAIL_state_init,
  FAIL_invalid_sid,
  FAIL_sid_used,
  FAIL_undefined_sub,
  FAIL_fallback,
  FAIL_nodataset,
  FAIL_nodrive,
  FAIL_nomapping,
  FAIL_type_mismatch,
  FAIL_nokey,
  FAIL_nosupersubs,
  FAIL_unknown_key,
  FAIL_datafetch,
  FAIL_nosubs,
  FAIL_module_undefined,
  FAIL_unused_module,
  FAIL_nodrive_for_symbol,
  FAIL_hasnodrive,
  FAIL_dataset_not_found,
  FAIL_hasnodrive_fb,
  FAIL_nofile,
} = ERRORS('https://github.com/playproject-io/datashell/tree/main/doc')
/*****************************************************************************/
window.STATEMODULE = status // @TODO: remove after finishing debugging!

module.exports = STATE
/******************************************************************************
  HELPER: LISTIFY
******************************************************************************/
function tolist (tree, prefix = '') {
  const result = []
  if (tree && tree._ && typeof tree._ === 'object') walk(tree._, prefix)
  return result
  function walk (current, prefix = '') {
    for (const key in current) {
      if (key === '$' && current[key]._ && typeof current[key]._ === 'object') {
        walk(current[key]._, prefix)
      } else {
        const path = prefix ? `${prefix}>${key}` : key
        result.push(path)
        if (current[key]?.$?._ && typeof current[key].$._ === 'object') {
          walk(current[key].$._, path)
        }
      }
    }
  }
}
/******************************************************************************
  ADMIN
******************************************************************************/
function admin (imported_db = localdb) {
  const modulepath = db
  status.ROOT_ID = modulepath
  db = imported_db()
  status.db = db
  // Version check and initialization
  status.fallback_check = db.read(['playproject_version']) != VERSION
  if (!status.fallback_check) return { on }
  db.wash()
  db.add(['playproject_version'], VERSION)
  return { on }
  function on (callback) { status.callback = callback }
}
/******************************************************************************
  STATE
******************************************************************************/
function STATE (address, modulepath, dependencies) {
  status.modulepaths[modulepath] = 0
  status.addresses[modulepath] = address

  // Variables (module-level)
  const local_status = status.local_statuses[modulepath] = {
    name: extract_filename(address),
    module_id: modulepath,
    deny: {},
    sub_modules: [],
    sub_instances: {}
  }

  const _statedb = defaults => statedb(local_status, defaults)
  if (!db) (_statedb.admin = admin, db = modulepath)
  return _statedb
  /******************************************************************************
    STATEDB
  ******************************************************************************/
  function statedb (local_status, fallback) {
    if (!status.ROOT_ID) throw new Error(FAIL_admin_access())
    const listify = tree => tolist(tree, modulepath)
    const tree = status.tree_pointers[modulepath]
    const data = fallback(status.args[modulepath], { listify, tree })

    local_status.fallback_instance = data.api

    local_status.fallback_module = new Function(`return ${fallback.toString()}`)()

    const super_id = modulepath.split(/>(?=[^>]*$)/)[0]

    const cond1 = super_id === status.current_node
    const cond2 = (status?.current_node?.split('>').length || 0) < super_id.split('>').length
    if (cond1) status.expected_imports[super_id].splice(status.expected_imports[super_id].indexOf(modulepath), 1)
    else if (cond2) {
      let temp = super_id
      while(temp !== status.current_node && temp.includes('>')){
//        status.open_branches[temp] = 0
        temp = temp.split(/>(?=[^>]*$)/)[0]
      }
    }
    else {
      let temp = status.current_node
      while(temp !== super_id && temp.includes('>')){
//        status.open_branches[temp] = 0
        temp = temp.split(/>(?=[^>]*$)/)[0]
      }
    }

    if (data._) {
//      status.open_branches[modulepath] = Object.values(data._).filter(node => node).length
      status.expected_imports[modulepath] = Object.keys(data._)
      status.current_node = modulepath
    }

    verify_imports(modulepath, dependencies, data)

    const updated_status = append_tree_node(modulepath, status)

    Object.assign(status.tree_pointers, updated_status.tree_pointers)
//    Object.assign(status.open_branches, updated_status.open_branches)

//    status.inits.push(init_module)
//    if (!Object.values(status.open_branches).reduce((acc, curr) => acc + curr, 0)) status.inits.forEach(init => init())
    init_module()

    var xtype
    const { public_api, private_api } = create_statedb_interface(local_status, modulepath, xtype = 'module')

    status.dataset = private_api

    const get = init_instance
    const extra_fallbacks = Object.entries(local_status.fallback_instance || {})
    extra_fallbacks.length && extra_fallbacks.forEach(([key]) => {
      get[key] = (sid) => get(sid, key)
    })
    if (!status.a2i[modulepath]) {
      status.i2a[status.a2i[modulepath] = encode(modulepath)] = modulepath
    }

    try {
      if (status.callback) status.callback({ type: 'create sdb', data: modulepath })
      return {
        id: modulepath,
        sdb: public_api,
        get: init_instance,
        io: io(status.a2i[modulepath], modulepath, status.callback)
        // sub_modules
      }
    } catch (error) { throw new Error(FAIL_id({ modulepath, error })) }
  }
  function append_tree_node (id, status) {
    const [super_id, name] = id.split(/>(?=[^>]*$)/)

    if (Object.keys(status.tree).length) {
      if (status.tree_pointers[super_id]) {
        status.tree_pointers[super_id]._[name] = { $: { _: {} } }
        status.tree_pointers[id] = status.tree_pointers[super_id]._[name].$
//        status.open_branches[super_id]--
      }
      else {
        let new_name = name
        let new_super_id = super_id
        while (!status.tree_pointers[new_super_id]) {
          const [next_super_id, temp_name] = new_super_id.split(/>(?=[^>]*$)/)
          if (temp_name === undefined) throw new Error(FAIL_state_init({
            id, tree_pointers: status.tree_pointers
          }))
          new_super_id = next_super_id
          new_name = temp_name + '>' + new_name
        }
        status.tree_pointers[new_super_id]._[new_name] = { $: { _: {} } }
        status.tree_pointers[id] = status.tree_pointers[new_super_id]._[new_name].$
//        if (!status.missing_supers.has(super_id)) status.open_branches[new_super_id]--
        status.missing_supers.add(super_id)
      }
    }
    else {
      status.tree[id] = { $: { _: {} } }
      status.tree_pointers[id] = status.tree[id].$
    }
    return status
  }
  function init_module () {
    const {statedata, state_entries, newstatus, updated_local_status} = get_module_data(local_status.fallback_module)
//    debugger
    statedata.orphan && (local_status.orphan = true)
    //side effects
    if (status.fallback_check) {
      Object.assign(status.root_module, newstatus.root_module)
      Object.assign(status.overrides, newstatus.overrides)
      console.log('Main module: ', statedata.id, '\n', state_entries)
      updated_local_status && Object.assign(local_status, updated_local_status)
      // console.log('Local status: ', local_status.fallback_instance, statedata.api)
      const old_fallback = local_status.fallback_instance

      if (local_status.fallback_instance ? local_status.fallback_instance?.toString() === statedata.api?.toString() : false)
        local_status.fallback_instance = statedata.api
      else
        local_status.fallback_instance = (args, tools) => {
          return statedata.api(args, tools, [old_fallback])
        }
      const extra_fallbacks = Object.entries(old_fallback || {})
      extra_fallbacks.length && extra_fallbacks.forEach(([key, value]) => {
        local_status.fallback_instance[key] = (args, tools) => {
          console.log('Extra fallback: ', statedata.api[key] ? statedata.api[key] : old_fallback[key])
          return (statedata.api[key] ? statedata.api[key] : old_fallback[key])(args, tools, [value])
        }
      })
      db.append(['state'], state_entries)
      db.add(['root_datasets'], [{ name: 'state' }])
      // add_source_code(statedata.inputs) // @TODO: remove side effect
    }
    const [sub_modules, symbol2ID, ID2Symbol, address2ID, ID2Address] = symbolfy(statedata, local_status)
    local_status.sub_modules = sub_modules
    Object.assign(status.s2i, symbol2ID)
    Object.assign(status.i2s, ID2Symbol)
    Object.assign(status.a2i, address2ID)
    Object.assign(status.i2a, ID2Address)

    if (status.root_module) { //Setup local data (module level)
      status.root_module = false
      statedata.admins && admins.push(...statedata.admins)
    }
    // @TODO: handle sub_modules when dynamic require is implemented
    // const sub_modules = {}
    // statedata.subs && statedata.subs.forEach(id => {
    //   sub_modules[db.read(['state', id]).type] = id
    // })
  }
  function init_instance (sid, fallback_key) {
    const fallback = local_status.fallback_instance[fallback_key] || local_status.fallback_instance
    const {statedata, state_entries, newstatus} = get_instance_data(sid, fallback)

    if (status.fallback_check) {
      Object.assign(status.root_module, newstatus.root_module)
      Object.assign(status.overrides, newstatus.overrides)
      Object.assign(status.tree, newstatus.tree)
      console.log('Main instance: ', statedata.id, '\n', state_entries)
      db.append(['state'], state_entries)
    }
    const [sub_instance, symbol2ID, ID2Symbol, address2ID, ID2Address] = symbolfy(statedata, local_status)
    local_status.sub_instances[statedata.id] = sub_instance
    Object.assign(status.s2i, symbol2ID)
    Object.assign(status.i2s, ID2Symbol)
    Object.assign(status.a2i, address2ID)
    Object.assign(status.i2a, ID2Address)
    var xtype
    const sdb = create_statedb_interface(local_status, statedata.id, xtype = 'instance')
    sdb.id = statedata.id

    const sanitized_event = {}
    statedata.net && Object.keys(statedata.net).forEach(node => {
      statedata.net[node].id = status.a2i[node] || (status.a2i[node] = encode(node))
    })

    status.callback && status.callback({ type:'create sdb', data:statedata.id })
    return {
      id: statedata.id,
      net: statedata.net,
      sdb: sdb.public_api,
      io: io(status.a2i[statedata.id], modulepath, status.callback),
    }
  }
  function get_module_data (fallback) {
    let data = db.read(['state', modulepath])
    if (status.fallback_check) {
      if (data) {
        var {sanitized_data, updated_status} = preprocess({ fun_status: status, fallback, xtype: 'module', pre_data: data })
      }
      else if (status.root_module) {
        var {sanitized_data, updated_status} = preprocess({ fun_status: status, fallback, xtype: 'module', pre_data: {id: modulepath}})
      }
      else {
        var {sanitized_data, updated_status, updated_local_status} = find_super({ xtype: 'module', fallback, fun_status:status, local_status })
      }
      data = sanitized_data.entry
    }
    return {
      statedata: data,
      state_entries: sanitized_data?.entries,
      newstatus: updated_status,
      updated_local_status
    }
  }
  function get_instance_data (sid, fallback) {
    let id = status.s2i[sid]

LESEZEICHEN: 'continue here' // fix demo2/example2

    if (id && (id.split(':')[0] !== modulepath || !id.includes(':'))) {
      throw new Error(FAIL_invalid_sid({ id, modulepath }))
    }
    if (status.used_ids.has(id)) {
      debugger
      throw new Error(FAIL_sid_used(id))
    }
    if (id) status.used_ids.add(id)
    let data = id && db.read(['state', id])
    let sanitized_data, updated_status = status
    if (status.fallback_check) {
      if (!data && !status.root_instance) {
        ;({sanitized_data, updated_status} = find_super({ xtype: 'instance', fallback, fun_status: status }))
      } else {
        ;({sanitized_data, updated_status} = preprocess({
          fun_status: status,
          fallback,
          xtype: 'instance',
          pre_data: data || {id: get_instance_path(modulepath)}
        }))
        updated_status.root_instance = false
      }
      data = sanitized_data.entry
    }
    else if (status.root_instance) {
      data = db.read(['state', id || get_instance_path(modulepath)])
      updated_status.tree = JSON.parse(JSON.stringify(status.tree))
      updated_status.root_instance = false
    }

    if (!data && local_status.orphan) {
      data = db.read(['state', get_instance_path(modulepath)])
    }
    return {
      statedata: data,
      state_entries: sanitized_data?.entries,
      newstatus: updated_status,
    }
  }
  function find_super ({ xtype, fallback, fun_status, local_status }) {
    let modulepath_super = modulepath.split(/\>(?=[^>]*$)/)[0]
    let modulepath_grand = modulepath_super.split(/\>(?=[^>]*$)/)[0]
    if (status.modulepaths[modulepath_super] !== undefined) {
      throw new Error(FAIL_undefined_sub({ modulepath, modulepath_super }))
    }
    const split = modulepath.split('>')
    let data
    const entries = {}
    if (xtype === 'module') {
      let name = split.at(-1)
      while(!data && modulepath_grand.includes('>')){
        data = db.read(['state', modulepath_super])
        const split = modulepath_super.split(/\>(?=[^>]*$)/)
        modulepath_super = split[0]
        name = split[1] + '>' + name
      }
      console.log(data)
      data.path = data.id = modulepath_super + '>' + name
      modulepath = modulepath_super + '>' + name
      local_status.name = name

      const super_data = db.read(['state', modulepath_super])
      super_data.subs.forEach((sub_id, i) => {
        if (sub_id === modulepath_super) {
          super_data.subs.splice(i, 1)
          return
        }
      })
      super_data.subs.push(data.id)
      entries[super_data.id] = super_data
    }
    else {
      //@TODO: Make the :0 dynamic
      let instance_path_super = modulepath_super + ':0'
      let temp
      while (!data && temp !== modulepath_super) {
        data = db.read(['state', instance_path_super])
        temp = modulepath_super
        modulepath_grand = modulepath_super = modulepath_super.split(/\>(?=[^>]*$)/)[0]
        instance_path_super = modulepath_super + ':0'
      }
      data.path = data.id = get_instance_path(modulepath)
      temp = null
      let super_data
      let instance_path_grand = modulepath_grand.includes('>') ? modulepath_grand + ':0' : modulepath_grand

      while (!super_data?.subs && temp !== modulepath_grand) {
        super_data = db.read(['state', instance_path_grand])
        temp = modulepath_grand
        modulepath_grand = modulepath_grand.split(/\>(?=[^>]*$)/)[0]
        instance_path_grand = modulepath_grand.includes('>') ? modulepath_grand + ':0' : modulepath_grand
      }

      super_data.subs.forEach((sub_id, i) => {
        if (sub_id === instance_path_super) {
          super_data.subs.splice(i, 1)
          return
        }
      })
      super_data.subs.push(data.id)
      entries[super_data.id] = super_data
    }
    data.name = split.at(-1)
    return {
      updated_local_status: local_status,
      ...preprocess({
        fun_status,
        fallback, xtype,
        pre_data: data,
        orphan_check: true, entries
      })
    }
  }
  function preprocess ({ fallback, xtype, pre_data = {}, orphan_check, fun_status, entries }) {
    const used_keys = new Set()
    let { id: pre_id, hubs: pre_hubs, mapping } = pre_data
    console.log('%c[PREPROCESS]', 'color: fuchsia;', pre_id)

    let fallback_data

    const listify = tree => tolist(tree, modulepath)
    const tree = status.tree_pointers[modulepath]
    const fallback_args = [status.args[pre_id], { listify, tree }]
    fallback_data = fallback(...fallback_args)

    try {
      validate(fallback_data, xtype)
    } catch (error) {
      throw new Error(FAIL_fallback({ pre_id, xtype, stack: error.stack }))
    }
    const overrides = fun_status.overrides[pre_id]
    if (overrides) {
      // console.log('Before: ', JSON.parse(JSON.stringify(fallback_data)))
      const override = overrides.fun.shift()
      fallback_data = override(...fallback_args, get_fallbacks({
        fallback_data, overrides: overrides.fun, modulepath, instance_path: pre_id
      }))
      // console.log('After: ', JSON.parse(JSON.stringify(fallback_data)))
      console.log('Override used: ', pre_id, overrides.by, )
      overrides.by.splice(0, 1)
      overrides.fun.splice(0, 1)
    }

    // console.log('fallback_data: ', fallback)
    fun_status.overrides = register_overrides({
      overrides: fun_status.overrides, tree: fallback_data, path: modulepath, id: pre_id, address
    })
    console.log('overrides: ', Object.keys(fun_status.overrides))
    orphan_check && (fallback_data.orphan = orphan_check)
    //This function makes changes in fun_status (side effect)
    /** Data stored in a entry in db by STATE (Schema):
     * entry:
     *  id (String): Node Path
     *  name (String/Optional): Any (To be used in theme_widget)
     *  type (String): Module Name for module / Module id for instances
     *  hubs (Array): List of hub-nodes
     *  subs (Array): List of sub-nodes
     *  inputs (Array): List of input files
    **/
    return {
      sanitized_data: sanitize_state({ local_id: '', entry: fallback_data, path: pre_id, xtype, mapping, entries }),
      updated_status: fun_status
    }

    function sanitize_state ({ local_id, entry, path, hub_entry, local_tree, entries = {}, xtype, mapping, xkey }) {
      ;[path, entry, local_tree] = extract_data({ local_id, entry, path, hub_entry, local_tree, xtype, xkey })

      entry.id =  path
      entry.name = entry.name || local_id.split(':')[0] || local_status.name
      mapping && (entry.mapping = mapping)

      entries = {...entries, ...sanitize_subs({ local_id, entry, path, local_tree, xtype, mapping })}
      delete entry._
      entries[entry.id] = entry
      // console.log('Entry: ', entry)
      return {entries, entry}
    }
    function extract_data ({ local_id, entry, path, hub_entry, xtype, xkey }) {
      if (local_id) {
        entry.hubs = [hub_entry.id]
        if (xtype === 'instance') {
          let temp_path = path.split(':')[0]
          temp_path = temp_path ? temp_path + '>' : temp_path
          const module_id = temp_path + local_id
          entry.type = module_id
          path = module_id + ':' + xkey
          var temp = Number(xkey)+1
          var temp2 = db.read(['state', path])
          while (temp2 || used_keys.has(path)) {
            path = module_id + ':' + temp
            temp2 = db.read(['state', path])
            temp++
          }
        }
        else {
          entry.type = local_id
          path = path ? path + '>' : ''
          path = path + local_id
        }
      }
      else {
        if (xtype === 'instance') {
          entry.type = local_status.module_id
        } else {
          var local_tree = JSON.parse(JSON.stringify(entry))
          // @TODO Handle JS file entry
          // console.log('pre_id:', pre_id)
          // const file_id = local_status.name + '.js'
          // entry.drive || (entry.drive = {})
          // entry.drive[file_id] = { $ref: address }
          entry.type = local_status.name
        }
        pre_hubs && (entry.hubs = pre_hubs)
      }
      return [path, entry, local_tree]
    }
    function sanitize_subs ({ local_id, entry, path, local_tree, xtype, mapping }) {
      const entries = {}
      if (!local_id) {
        entry.subs = []

        if (entry.drive) {
          // entry.drive.theme && (entry.theme = entry.drive.theme)
          // entry.drive.lang && (entry.lang = entry.drive.lang)
          entry.inputs = []
          const new_drive = []
          const map_drive = {}
          const path_def = {}
          Object.entries(entry.drive).forEach(([dataset_type, dataset]) => {
            if (dataset_type.split('/')[1]) {
              path_def[dataset_type] = dataset
              return
            }
            dataset_type = dataset_type.split('/')[0]

            const new_dataset = { files: [], mapping: {}, name: 'default' }
            Object.entries(dataset).forEach(([key, value]) => {
              new_dataset.files.push(append_file(key, value, entry, entries))
            })
            new_dataset.id = entry.id + '.default.' + dataset_type + '.dataset'
            Object.assign(new_dataset, fill_dataset(new_dataset, dataset_type))
            activate_dataset(new_dataset, dataset_type)
            new_drive.push(new_dataset.id)

          })
          if (Object.keys(path_def).length) {
            Object.entries(path_def).forEach(([path, value]) =>{
              const [dataset_type, file_name] = path.split('/')
              const new_dataset = map_drive[dataset_type] || (map_drive[dataset_type] = { files: [], mapping: {}, name: 'default' })

              if (!new_dataset.id) {
                new_dataset.id = entry.id + '.default.' + dataset_type + '.dataset'
                if(new_drive.includes(new_dataset.id)){
                  console.warn(`Both JSON and path definitions used for dataset "${dataset_type}" in the drive of "${entry.id}"`)
                  return
                }
                Object.assign(new_dataset, fill_dataset(new_dataset, dataset_type))
              }
              new_dataset.files.push(append_file(file_name, value, entry, entries))
              activate_dataset(new_dataset, dataset_type)
            })
            new_drive.push(...Object.values(map_drive).map(dataset => dataset.id))
          }
          entry.drive = new_drive
        }
        else entry.drive = []

        if (entry._) {
          //@TODO refactor when fallback structure improves
          Object.entries(entry._).forEach(([local_id, value]) => {
            const val = sanitize_mapping(value.mapping)
            if (typeof value === 'object' && value !== null) value.mapping = val
            Object.entries(value).forEach(([key, override]) => {
              if (key === 'mapping' || (key === '$' && xtype === 'instance')) return
              const sub_instance = sanitize_state({ local_id, entry: value, path, hub_entry: entry, local_tree, xtype: key === '$' ? 'module' : 'instance', mapping: value['mapping'], xkey: key }).entry
              entries[sub_instance.id] = JSON.parse(JSON.stringify(sub_instance))
              entry.subs.push(sub_instance.id)
              used_keys.add(sub_instance.id)
            })
          })
        }
      }
      return entries

      function append_file (key, value, entry, entries) {
        const sanitized_file = sanitize_file(key, value, entry, entries)
        entries[sanitized_file.id] = sanitized_file
        return sanitized_file.id
      }
      function fill_dataset (dataset, dataset_type) {
        dataset.type = status.dataset_types[dataset_type] || dataset_type
        dataset.xtype = dataset_type
        dataset.id = db.gen_id(dataset.id)
        dataset.node_id = entry.id
        entries[dataset.id] = dataset
      }
      function activate_dataset (dataset, dataset_type) {
        let check_name = true
        entry.inputs.forEach(dataset_id => {
          const ds = entries[dataset_id]
          if (ds.type === dataset.type) check_name = false
        })
        check_name && entry.inputs.push(dataset.id)

        if (status.root_module) fun_status.root_datasets.push(dataset.type)
        else {
          const hub_entry = db.read(['state', entry.hubs[0]])
          if(!hub_entry.inputs) throw new Error(FAIL_nodrive(hub_entry.id))
          if(!mapping?.[dataset_type]) throw new Error(FAIL_nomapping({
            dataset_type, subid: entry.id, id: hub_entry.id, type: dataset.type
          }))
          const mapped_file_type = mapping[dataset.type]
          hub_entry.inputs.some(input_id => {
            const input = db.read(['state', input_id])
            if (mapped_file_type === input.type) {
              input.mapping[entry.id] = dataset.id
              entries[input_id] = input
              return
            }
          })
        }
      }
      function sanitize_mapping (mapping) {
        if (!mapping) return mapping
        console.log('Sanitizing mapping: ', mapping, entry.id)
        const new_mapping = mapping
        Object.entries(mapping).forEach(([key, value]) => {
          if (status.root_datasets.includes(value)) {
            fun_status.dataset_types[key] = value
          }
          else if (status.dataset_types[value]) {
            new_mapping[key] = status.dataset_types[value]
            fun_status.dataset_types[key] = status.dataset_types[value]
          }
          else throw new Error(FAIL_nodataset({ value, subid: entry.id }))
        })
        return new_mapping
      }
    }
    function sanitize_file (file_id, file, entry, entries) {
      const type = file_id.split('.').at(-1)

      if (!isNaN(Number(file_id))) return file_id

      const raw_id = local_status.name + '.' + type
      file.id = raw_id
      file.name = file.name || file_id
      file.type = type
      file[file.type === 'js' ? 'subs' : 'hubs'] = [entry.id]
      if (file.$ref) file.address = file.address || address
      file.id = db.gen_id(file.id)
      while (entries[file.id]) {
        const no = file.id.split(':')[1]
        file.id = raw_id + ':' + (Number(no || 0) + 1)
      }
      return file
    }
  }
}

// External Function (helper)
function validate (data, xtype) {
  /**  Expected structure and types
   * Sample : "key1|key2:*:type1|type2"
   * ":" : separator
   * "|" : OR
   * "*" : Required key
   * */
  const expected_structure = {
    'api::function': () => {},
    '_::object': {
      ":*:object|number": {
        ":*:function|string|object": '',
        "mapping::": {}
      }
    },
    'drive::object': {
      "::object": {
        "::object|string": { // Required key, any name allowed
          "raw|$ref:*:object|string": {}, // data or $ref are names, required, object or string are types
          "$ref": "string",
          "address": "string",
        }
      },
    },
    'net::object': {}
  }

  validate_shape(data, expected_structure)

  function validate_shape (obj, expected, super_node = 'root', path = '') {
    const keys = Object.keys(obj)
    const values = Object.values(obj)
    let strict = Object.keys(expected).length

    const all_keys = []
    Object.entries(expected).forEach(([expected_key, expected_value]) => {
      let [expected_key_names, required, expected_types] = expected_key.split(':')
      expected_types = expected_types ? expected_types.split('|') : [typeof(expected_value)]
      let absent = true
      if (expected_key_names) expected_key_names.split('|').forEach(expected_key_name => {
        const value = obj[expected_key_name]
        if (value !== undefined) {
          all_keys.push(expected_key_name)
          const type = typeof(value)
          absent = false

          if (expected_types.includes(type))
            type === 'object' && validate_shape(value, expected_value, expected_key_name, path + '/' + expected_key_name)
          else throw new Error(FAIL_type_mismatch({
            expected_types, type, expected_key_name, path
          }))
        }
      })
      else {
        strict = false
        values.forEach((value, index) => {
          absent = false
          const type = typeof(value)

          if (expected_types.includes(type))
            type === 'object' && validate_shape(value, expected_value, keys[index], path + '/' + keys[index])
          else throw new Error(FAIL_type_mismatch({
            expected_types, type, expected_key_name: keys[index], path
          }))
        })
      }
      if (absent && required) {
        if (expected_key_names) throw new Error(FAIL_nokey({ expected_key_names, path }))
        else throw new Error(FAIL_nosupersubs({ super_node, path }))
      }
    })

    strict && keys.forEach(key => {
      if (!all_keys.includes(key)) throw new Error(FAIL_unknown_key({ key, path }))
    })
  }
}
function extract_filename (address) {
  const parts = address.split('/node_modules/')
  const last = parts.at(-1).split('/')
  if (last.at(-1) === 'index.js') return last.at(-2)
  return last.at(-1).slice(0, -3)
}
function get_instance_path (modulepath, modulepaths = status.modulepaths) {
  return modulepath + ':' + modulepaths[modulepath]++
}
async function get_input ({ id, name, $ref, type, raw, address }) {
  const xtype = (typeof(id) === "number" ? name : id).split('.').at(-1)
  let result = db.read(['state', id])?.raw
  if (!result) {
    if (raw === undefined) {
      // Patch: Prepend GitHub project name if running on GitHub Pages
      let github_project = ''
      if (typeof window !== 'undefined' && window.location.hostname.endsWith('github.io')) {
        const path_parts = window.location.pathname.split('/').filter(Boolean)
        if (path_parts.length > 0 && !$ref.startsWith('/' + path_parts[0])) {
          github_project = '/' + path_parts[0] + ($ref.startsWith('/') ? '' : '/')
        }
      }
      const ref = github_project + address.substring(0, address.lastIndexOf("/")) + '/'  + $ref
      const response = await fetch(ref, { cache: 'no-store' })

      if (!response.ok) throw new Error(FAIL_datafetch({ ref, id }))
      else
        result = await response[xtype === 'json' ? 'json' : 'text']()
    }
    else result = raw
    db.add(['state', id], { id, name, type, address, $ref, raw: result })
  }
  return result
}
function compare(before, after, address) {
  if (typeof after !== "object" || after === null) return after

  for (const key in after) {
    if (key === "$ref") {
      if (!before || before[key] !== after[key]) {
        //@TODO: What if before is from an override not fallback
        after.address = address
      }
    } else {
      after[key] = compare(before ? before[key] : undefined, after[key], address)
    }
  }
  return after
}
//Unavoidable side effect
function add_source_code (hubs) {
  hubs.forEach(async id => {
    const data = db.read(['state', id])
    if (data.type === 'js') {
      data.data = await get_input(data)
      db.add(['state', data.id], data)
      return
    }
  })
}
function verify_imports (id, imports, data) {
  const state_address = imports.find(imp => imp.includes('STATE'))
  HELPER_MODULES.push(state_address)
  imports = imports.filter(imp => !HELPER_MODULES.includes(imp))
  if (!data._) {
    if (imports.length > 1) {
      imports.splice(imports.indexOf(state_address), 1)
      const module_id = status.local_statuses[id].module_id
      throw new Error(FAIL_nosubs({ imports, module_id }))
    }
    else return
  }
  const fallback_imports = Object.keys(data._)

  imports.forEach(imp => {
    let check = true
    fallback_imports.forEach(fallimp => {
      if (imp === fallimp) check = false
    })

    if (check) throw new Error(FAIL_module_undefined({
      imp, id: status.local_statuses[id].module_id
    }))
  })

  fallback_imports.forEach(fallimp => {
    let check = true
    imports.forEach(imp => {
      if (imp === fallimp) check = false
    })

    if (check) throw new Error(FAIL_unused_module({
      fallimp, id: status.local_statuses[id].module_id
    }))
  })
}
function symbolfy (data) {
  const i2s = {}
  const s2i = {}
  const i2a = {}
  const a2i = {}
  const subs = []
  data.subs && data.subs.forEach(sub => {
    const substate = db.read(['state', sub])
    i2a[a2i[sub] = encode(sub)] = sub
    s2i[i2s[sub] = Symbol(a2i[sub])] = sub
    subs.push({ sid: i2s[sub], type: substate.type })
  })
  return [subs, s2i, i2s, a2i, i2a]
}
function encode(text) {
  let code = ''
  while (code.length < 10) {
    for (let i = 0; i < text.length && code.length < 10; i++) {
      code += Math.floor(10 + Math.random() * 90)
    }
  }
  return code
}

function register_overrides ({overrides, address, ...args}) {
  const { id: root_id } = args
  recurse(args)
  return overrides
  function recurse ({ tree, path = '', id, xtype = 'instance', local_modulepaths = {} }) {

    tree._ && Object.entries(tree._).forEach(([type, instances]) => {
      const sub_path = path + '>' + type
      Object.entries(instances).forEach(([id, branch]) => {
        const resultant_path = id === '$' ? sub_path : sub_path + ':' + id
        if (typeof(branch) === 'function') {
          const override = mutate
          function mutate (...all) {
            const before = JSON.parse(JSON.stringify(all[2][0]()))
            const after = compare(before, branch(...all), address)
            if (after.api) {
              const api = after.api
              after.api = (...all) => {
                const before = JSON.parse(JSON.stringify(all[2][0]()))
                return compare(before, api(...all), address)
              }
            }
            return after
          }
          if (overrides[resultant_path]) {
            overrides[resultant_path].fun.push(override)
            overrides[resultant_path].by.push(root_id)
          }
          else
            overrides[resultant_path] = {fun: [override], by: [root_id]}
        }
        else if ( ['object', 'string'].includes(typeof(branch)) && id !== 'mapping' && branch._ === undefined)
          status.args[resultant_path] = structuredClone(branch)
        else
          recurse({ tree: branch, path: sub_path, id, xtype, local_modulepaths })
      })
    })
  }
}
function get_fallbacks ({ fallback_data, overrides, modulepath, instance_path }) {
  return [mutated_fallback, ...overrides]

  function mutated_fallback () {
    const data = fallback_data

    merge_trees(data, modulepath)
    return data

    function merge_trees (data, path) {
      if (data._) {
        Object.entries(data._).forEach(([type, data]) => merge_trees(data, path + '>' + type.split('$')[0].replace('.', '>')))
      } else {
        data.$ = { _: status.tree_pointers[path]?._ }
      }
    }
  }
}

function download (data, name) {
  const dataStr = JSON.stringify(data, null, 2)
  const blob = new Blob([dataStr], { type: 'application/json' })
  const a = document.createElement('a')
  a.href = URL.createObjectURL(blob)
  a.download = `${name}.json`
  a.click()
}
// Public Function
function create_statedb_interface (local_status, node_id, xtype) {
  const drive = {
    get: (path) => get(path), has: (path) => has(path),
    put: (path, buffer) => put(path, buffer), list: (path) => list(path)
  }
  const admin_drive = { get, has, put, list }
  const api =  {
    public_api: {
      watch, get_sub, drive, get: get_drive
    },
    private_api: {
      drive: admin_drive,
      xget: (id) => db.read(['state', id]),
      get_all: () => db.read_all(['state']),
      get_dataset,
      register,
      load: (snapshot) => {
        db.wash()
        Object.entries(snapshot).forEach(([key, value]) => {
          db.add([key], JSON.parse(value), true)
        })
        window.location.reload()
      },
      swtch,
      unregister,
      status,
      export_db,
      import_db,
      export_root,
      import_root,
      register_callback
    }
  }
  node_id === status.ROOT_ID && (api.public_api.admin = api.private_api)
  return api
  // -------------------------------------
  async function watch (listener, on) {
    if (on) status.services[node_id] = Object.keys(on)
    const data = db.read(['state', node_id])
    if (listener) {
      ;(status.listeners[data.id] = status.listeners[data.id] || []).push(listener)
      await listener(await make_input_map(data.inputs))
    }
    return xtype === 'module' ? local_status.sub_modules : local_status.sub_instances[node_id]
  }
  // VS. @TODO: make watch a synchronous function
  async function watch2 (listener, on) {
    if (on) status.services[node_id] = Object.keys(on)
    const data = db.read(['state', node_id])
    if (listener) {
      ;(status.listeners[data.id] = status.listeners[data.id] || []).push(listener)
      Promise.resolve().then(notify)
    }
    console.log('[watch]')
    return xtype === 'module' ? local_status.sub_modules : local_status.sub_instances[node_id]
    async function notify () {
      console.log('[notify]')
      const opts = await make_input_map(data.inputs)
      await listener(opts)
    }
  }
  // -------------------------------------
  function register_callback (callbacks) {
    status.callbacks.push(...callbacks)
  }
  function export_db (result) {
    const datasets = get_dataset(result)
    result.dataset = {}
    datasets.forEach(dataset_id => {
      const dataset = db.read(['state', dataset_id])
      const node_id = dataset.node_id
      const files = dataset.files || []
      result.dataset[node_id] = {}
      files.forEach(file_id => {
        const file = db.read(['state', file_id])
        result.dataset[node_id][file.name] = { raw: file.raw }
      })
    })

    download(result, `${result.name}-${result.type}`)
  }
  function import_db (data) {
    register(data)
    status.callback({ type: 'import', data })
  }
  function export_root ({name}) {
    const result = db.read_all([name])
    console.log(name, result)
    download(result, name)
  }
  function import_root (data, name) {
    Object.entries(data).forEach(([key, value]) => {
      db.add([name, key], value)
    })
    console.log('hello')
    db.push(['root_datasets'], { name: name })
    status.callback({ type: 'import', data })
  }
  function get_sub (type) {
    const subs = xtype === 'module' ? local_status.sub_modules : local_status.sub_instances[node_id]
    return subs.filter(sub => sub.type === type)
  }
  function get_dataset ({ root = 'state', type: dataset_type, name: dataset_name } = { root: 'state'}) {
    const node = db.read([root, status.ROOT_ID])
    if (dataset_type) {
      const dataset_list = []
      node.drive.forEach(dataset_id => {
        const dataset = db.read([root, dataset_id])
        if (dataset.type === dataset_type) dataset_list.push(dataset.name)
      })
      if (dataset_name) {
        return recurse(status.ROOT_ID, dataset_type)
      }
      return dataset_list
    }
    const datasets = []
    node.inputs && node.inputs.forEach(dataset_id => {
      datasets.push(db.read([root, dataset_id]).type)
    })
    return datasets

    function recurse (node_id, dataset_type){
      const node_list = []
      const entry = db.read(['state', node_id])
      entry.drive && entry.drive.forEach(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if (dataset.type === dataset_type && dataset.name === dataset_name) {
          node_list.push(dataset_id)
          return
        }
      })
      entry.subs && entry.subs.forEach(sub_id => node_list.push(...recurse(sub_id, dataset_type)))
      return node_list
    }
  }
  function register ({ type: dataset_type, name: dataset_name, dataset}) {
    Object.entries(dataset).forEach(([node_id, files]) => {
      const new_dataset = { files: [] }
      const node = db.read(['state', node_id])

      Object.entries(files).forEach(([file_id, file]) => {
        const type = file_id.split('.').at(-1)

        file.id = db.gen_id(node.name + '.' + type)
        file.name = file_id
        file.type = type
        file[file.type === 'js' ? 'subs' : 'hubs'] = [node_id]


        db.add(['state', file.id], file)
        new_dataset.files.push(file.id)
      })

      new_dataset.id = db.gen_id(node_id + '.' + dataset_name + '.' + dataset_type + '.dataset')
      new_dataset.name = dataset_name
      new_dataset.type = dataset_type
      //@TODO: Make dataset xtypes dynamic
      new_dataset.xtype = dataset_type
      new_dataset.node_id = node_id

      node.drive.push(new_dataset.id) //@TODO: Rethink how to simplify this push
      db.add(['state', node.id], node)
      db.add(['state', new_dataset.id], new_dataset)
    })
    console.log(' registered ' + dataset_name + '.' + dataset_type)
  }
  function unregister ({ type: dataset_type, name: dataset_name } = {}) {
    return recurse(status.ROOT_ID)

    function recurse (node_id){
      const node = db.read(['state', node_id])
      node.drive && node.drive.some(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if (dataset.name === dataset_name && dataset.type === dataset_type) {
          node.drive.splice(node.drive.indexOf(dataset_id), 1)
          return true
        }
      })
      node.inputs && node.inputs.some(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if (dataset.name === dataset_name && dataset.type === dataset_type) {
          node.inputs.splice(node.inputs.indexOf(dataset_id), 1)
          swtch(dataset_type)
          return true
        }
      })
      db.add(['state', node_id], node)
      node.subs.forEach(sub_id => recurse(sub_id))
    }
  }
  function swtch ({ type: dataset_type, name: dataset_name = 'default'}) {
    recurse(dataset_type, dataset_name, status.ROOT_ID)

    async function recurse (target_type, target_name, id) {
      const node = db.read(['state', id])

      let target_dataset
      node.drive && node.drive.forEach(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if (target_name === dataset.name && target_type === dataset.type) {
          target_dataset = dataset
          return
        }
      })
      if (target_dataset) {
        node.inputs.forEach((dataset_id, i) => {
          const dataset = db.read(['state', dataset_id])
          if (target_type === dataset.type) {
            node.inputs.splice(i, 1)
            return
          }
        })
        node.inputs.push(target_dataset.id)
      }
      db.add(['state', id], node)
      const input_map = await make_input_map(node.inputs)
      status.listeners[id] && status.listeners[id].forEach(async listener => {
        await listener(input_map)
      })
      node.subs && node.subs.forEach(sub_id => {
        const subdataset_id = target_dataset?.mapping?.[sub_id]
        recurse(target_type, db.read(['state', subdataset_id])?.name || target_name, sub_id)
      })
    }
  }
  function get_drive (sid){
    const id = status.s2i[sid]
    if (!id) throw new Error(FAIL_nodrive_for_symbol({ sid }))
    return {
      list: (path) => list(path, id),
      get: (path) => get(path, id),
      has: (path) => has(path, id),
      on
    }
    function on (listener) {
      (status.listeners[id] = status.listeners[id] || []).push(listener)
    }
  }
  //Node specific functions
  function list (path, id = node_id) {
    const node = db.read(['state', id])
    if (!node.drive) throw new Error(FAIL_hasnodrive({ id }))
    const dataset_names = node.drive.map(dataset_id => {
      return dataset_id.split('.').at(-2) + '/'
    })
    if (path) {
      let index
      dataset_names.some((dataset_name, i) => {
        if (path.includes(dataset_name)) {
          index = i
          return true
        }
      })
      if (index === undefined) throw new Error(FAIL_dataset_not_found({
        path, name: node.name
      }))
      const dataset = db.read(['state', node.drive[index]])
      return dataset.files.map(fileId => {
        const file = db.read(['state', fileId])
        return file.name
      })
    }
    return dataset_names
  }
  async function get (path, id = node_id) {
    const [dataset_name, file_name] = path.split('/')
    const node = db.read(['state', id])
    let dataset
    if (!node.drive) throw new Error(FAIL_hasnodrive_fb ({ id: node.id }))


    node.inputs.some(dataset_id => {
      if (dataset_name === dataset_id.split('.').at(-2)) {
        dataset = db.read(['state', dataset_id])
        return true
      }
    })
    if (!dataset) throw new Error(FAIL_dataset_not_found({
      path: dataset_name, name: node.name
    }))
    let target_file
    for (const file_id of dataset.files) {
      const file = db.read(['state', file_id])
      if (file.name === file_name) {
        target_file =  { id: file.id, name: file.name, type: file.type, raw: await get_input(file)}
        break
      }
    }
    if (!target_file) throw new Error(FAIL_nofile({ path, id: node.id }))
    return target_file
  }
  async function put (path, buffer, id = node_id) {
    const [dataset_name, filename] = path.split('/')
    let dataset
    const node = db.read(['state', id])
    node.drive.some(dataset_id => {
      if (dataset_name === dataset_id.split('.').at(-2)) {
        dataset = db.read(['state', dataset_id])
        return true
      }
    })
    if (!dataset) throw new Error(FAIL_dataset_not_found({
      path: dataset_name, name: node.name
    }))
    const type = filename.split('.').pop()
    const raw_id = node.name + '.' + type
    const file = {
      id: raw_id,
      name: filename,
      type,
      raw: buffer
    }
    for (const file_id of dataset.files) {
      const temp_file = db.read(['state', file_id])
      if (temp_file.name === filename) {
        file.id = file_id
        break
      }
    }
    if (!dataset.files.includes(file.id)) {
      file.id = db.gen_id(file.id)
      dataset.files.push(file.id)
      db.add(['state', dataset.id], dataset)
    }
    db.add(['state', file.id], file)
    const input_map = await make_input_map(node.inputs)
    status.listeners[node.id].forEach(async listener => await listener(input_map))
    status.callback && status.callback({ type: 'put', data: id })
    return { id: file.id, name: filename, type, raw: buffer }
  }
}

/******************************************************************************
  HELPER: HAS
******************************************************************************/
function has (path, id = node_id) {
  const [dataset_name, filename] = path.split('/')
  let dataset
  const node = db.read(['state', id])
  node.drive.some(dataset_id => {
    if (dataset_name === dataset_id.split('.').at(-2)) {
      dataset = db.read(['state', dataset_id])
      return true
    }
  })
  if (!dataset) throw new Error(FAIL_dataset_not_found({
    path: dataset_name, name: node.name
  }))
  return dataset.files.some(file_id => {
    const file = db.read(['state', file_id])
    return file && file.name === filename
  })
}
/******************************************************************************
  HELPER: MAKE_INPUT_MAP
******************************************************************************/
async function make_input_map (inputs) {
  const input_map = []
  if (inputs) {
    await Promise.all(inputs.map(async input => {
      let files = []
      const dataset = db.read(['state', input])
      await Promise.all(dataset.files.map(async file_id => {
        const input_state = db.read(['state', file_id])
        files.push(dataset.id.split('.').at(-2) + '/' + input_state.name)
      }))
      input_map.push({ type: dataset.xtype, paths: files })
    }))
  }
  return input_map
}
/******************************************************************************
  HELPERS: ERRORS
******************************************************************************/
function ERRORS (url) {
  const text = `\nFor more info visit`
  const FALLBACK_POST_ERROR = `${text} ${url}/state/temp.md#defining-fallbacks`
  const FALLBACK_SYNTAX_POST_ERROR = `${text} ${url}/state/temp.md#key-descriptions`
  const FALLBACK_SUBS_POST_ERROR = `${text} ${url}/state/temp.md#shadow-dom-integration`
  return {
    FAIL_admin_access () {
      return 'Admin access required! Call statedb.admin() first.' + FALLBACK_POST_ERROR
    },
    FAIL_id ({ error, modulepath }) {
      return `ID: ${modulepath}\n` + error
    },
    FAIL_state_init ({ id, tree_pointers }) {
      return `STATE module wasnt properly initialized in preceeding path segments of "${
      id}" first, but so far has only been initialized in:\n* ${
      Object.keys(tree_pointers).join('\n* ')}`
    },
    FAIL_invalid_sid ({ id, modulepath }) {
      return `Access denied! Wrong SID '${id}' used by instance of '${
      modulepath}'` + FALLBACK_SUBS_POST_ERROR
    },
    FAIL_sid_used (id) {
      return `Access denied! SID '${id}' is already used` + FALLBACK_SUBS_POST_ERROR
    },
    FAIL_undefined_sub ({ modulepath, modulepath_super }) {
      return `Node "${modulepath}" is not defined in the fallback of "${
      modulepath_super}"` + FALLBACK_SUBS_POST_ERROR
    },
    FAIL_fallback ({ pre_id, xtype, stack }) {
      return `in fallback function of ${pre_id} ${xtype}\n${stack}`
    },
    FAIL_nodataset ({ value, subid }) {
      return `Mapped dataset "${value}" of "${
      subi,d}" can't be mapped to any root datasets` + FALLBACK_POST_ERROR
    },
    FAIL_nodrive (id) {
      return `Node "${id}" has no "drive" defined in its fallback` + FALLBACK_SUBS_POST_ERROR
    },
    FAIL_nomapping ({ dataset_type, subid, id, type }) {
      return `No mapping found for dataset "${dataset_type}" of subnode "${
      subid}" in node "${id}"\nTip: Add a mapping prop for "${
      type}" dataset in "${id}"'s fallback for "${subid}"` + FALLBACK_POST_ERROR
    },
    FAIL_type_mismatch ({ expected_types, type, expected_key_name, path }) {
      return `Type mismatch: Expected "${expected_types.join(' or ')}" got "${
      type}" for key "${expected_key_name}" at:` + path + FALLBACK_POST_ERROR
    },
    FAIL_nokey ({ expected_key_names, path }) {
      return `Can't find required key "${expected_key_names.replace('|', ' or ')
      }" at: ` + path + FALLBACK_POST_ERROR
    },
    FAIL_nosupersubs ({ super_node, path }) {
      return `No sub-nodes found for super key "${super_node
      }" at sub: ` + path + FALLBACK_POST_ERROR
    },
    FAIL_unknown_key ({ key, path }) {
      return `Unknown key detected: '${key}' is an unknown property at: ${
      path || 'root'}` + FALLBACK_POST_ERROR
    },
    FAIL_datafetch ({ ref, id }) {
      return `Failed to fetch data from '${ref}' for '${id}'` + FALLBACK_SYNTAX_POST_ERROR
    },
    FAIL_nosubs ({ imports, module_id }) {
      return `No sub-nodes found for required modules "${imports.join(', ')
      }" in the fallback of "${module_id}"` + FALLBACK_POST_ERROR
    },
    FAIL_module_undefined ({ imp, id }) {
      return 'Required module "'+imp+'" is not defined in the fallback of '+
      id + FALLBACK_POST_ERROR
    },
    FAIL_unused_module ({ fallimp, id }) {
      return 'Module "'+fallimp+'" defined in the fallback of '+id+' is not required'
    },
    FAIL_nodrive_for_symbol ({ sid }) {
      return `No drive found for symbol "${sid}"`
    },
    FAIL_hasnodrive ({ id }) {
      return `Node "${id}" has no drive`
    },
    FAIL_dataset_not_found ({ path, name }) {
      return `Dataset "${path}" not found in node "${name}"`
    },
    FAIL_hasnodrive_fb ({ id }) {
      return `Node ${id} has no drive defined in its fallback` + FALLBACK_POST_ERROR
    },
    FAIL_nofile ({ path, id }) {
      return `File "${path}" not found in node "${id}"`
    },
  }
}

