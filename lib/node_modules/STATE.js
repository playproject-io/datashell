const localdb = require('localdb')
const io = require('io')

const db = localdb()
/** Data stored in a entry in db by STATE (Schema): 
 * id (String): Node Path 
 * name (String/Optional): Any (To be used in theme_widget)
 * type (String): Module Name for module / Module id for instances
 * hubs (Array): List of hub-nodes
 * subs (Array): List of sub-nodes
 * inputs (Array): List of input files
 */
// Constants and initial setup (global level)
const VERSION = 13
const HELPER_MODULES = ['io', 'localdb', 'STATE']
const FALLBACK_POST_ERROR = '\nFor more info visit https://github.com/alyhxn/playproject/blob/main/doc/state/temp.md#defining-fallbacks'
const FALLBACK_SYNTAX_POST_ERROR = '\nFor more info visit https://github.com/alyhxn/playproject/blob/main/doc/state/temp.md#key-descriptions'
const FALLBACK_SUBS_POST_ERROR = '\nFor more info visit https://github.com/alyhxn/playproject/blob/main/doc/state/temp.md#shadow-dom-integration'
const status = {
  root_module: true, 
  root_instance: true, 
  overrides: {},
  tree: {},
  tree_pointers: {},
  modulepaths: {},
  inits: [],
  open_branches: {},
  db,
  local_statuses: {},
  listeners: {},
  missing_supers: new Set(),
  imports: {},
  expected_imports: {},
  used_ids: new Set(),
  a2i: {},
  i2a: {},
  s2i: {},
  i2s: {},
  services: {},
  args: {},
  helpers: {
    listify
  }
}
window.STATEMODULE = status

// Version check and initialization

status.fallback_check = Boolean(check_version())
status.fallback_check && db.add(['playproject_version'], VERSION)


// Symbol mappings
let admins = [0]

// Inner Function
function STATE (address, modulepath, dependencies) {
  !status.ROOT_ID && (status.ROOT_ID = modulepath)
  status.modulepaths[modulepath] = 0
  //Variables (module-level)
  
  const local_status = {
    name: extract_filename(address),
    module_id: modulepath,
    deny: {},
    sub_modules: [],
    sub_instances: {}
  }
  status.local_statuses[modulepath] = local_status
  return statedb
  
  function statedb (fallback) {
    const data = fallback(status.args[modulepath], { listify: tree => listify(tree, modulepath), tree: status.tree_pointers[modulepath] })
    local_status.fallback_instance = data.api
    const super_id = modulepath.split(/>(?=[^>]*$)/)[0]
    
    if(super_id === status.current_node){
      status.expected_imports[super_id].splice(status.expected_imports[super_id].indexOf(modulepath), 1)
    }
    else if((status?.current_node?.split('>').length || 0) < super_id.split('>').length){
      let temp = super_id
      while(temp !== status.current_node && temp.includes('>')){
        status.open_branches[temp] = 0
        temp = temp.split(/>(?=[^>]*$)/)[0]
      }
    }
    else{
      let temp = status.current_node
      while(temp !== super_id && temp.includes('>')){
        status.open_branches[temp] = 0
        temp = temp.split(/>(?=[^>]*$)/)[0]
      }
    }

    if(data._){
      status.open_branches[modulepath] = Object.values(data._).filter(node => node).length
      status.expected_imports[modulepath] = Object.keys(data._)
      status.current_node = modulepath
    }

    local_status.fallback_module = new Function(`return ${fallback.toString()}`)()
    verify_imports(modulepath, dependencies, data)
    const updated_status = append_tree_node(modulepath, status)
    Object.assign(status.tree_pointers, updated_status.tree_pointers)
    Object.assign(status.open_branches, updated_status.open_branches)
    status.inits.push(init_module)
    
    // console.log(Object.values(status.open_branches).reduce((acc, curr) => acc + curr, 0))
    if(!Object.values(status.open_branches).reduce((acc, curr) => acc + curr, 0)){
      status.inits.forEach(init => init())
    }
    
    const sdb = create_statedb_interface(local_status, modulepath, xtype = 'module')
    sdb.id = modulepath
    status.dataset = sdb.private_api

    const get = init_instance
    const extra_fallbacks = Object.entries(local_status.fallback_instance || {})
    extra_fallbacks.length && extra_fallbacks.forEach(([key]) => {
      get[key] = (sid) => get(sid, key)
    })
    if(!status.a2i[modulepath]){
      status.i2a[status.a2i[modulepath] = encode(modulepath)] = modulepath
    }
    try {
      return {
      id: modulepath,
      sdb: sdb.public_api,
      get: init_instance,
      io: io(status.a2i[modulepath], modulepath)
      // sub_modules
    }
    } catch (error) {
      throw new Error(`ID: ${modulepath}\n`+error)
    }
    
  }
  function append_tree_node (id, status) {
    const [super_id, name] = id.split(/>(?=[^>]*$)/)

    if(Object.keys(status.tree).length){
      if(status.tree_pointers[super_id]){
        status.tree_pointers[super_id]._[name] = { $: { _: {} } }
        status.tree_pointers[id] = status.tree_pointers[super_id]._[name].$
        status.open_branches[super_id]--
      }
      else{
        let new_name = name
        let [new_super_id, temp_name] = super_id.split(/>(?=[^>]*$)/)

        new_name = temp_name + '>' + new_name

        while(!status.tree_pointers[new_super_id]){
          [new_super_id, temp_name] = new_super_id.split(/>(?=[^>]*$)/)
          new_name = temp_name + '>' + new_name
        }
        status.tree_pointers[new_super_id]._[new_name] = { $: { _: {} } }
        status.tree_pointers[id] = status.tree_pointers[new_super_id]._[new_name].$
        if(!status.missing_supers.has(super_id))
          status.open_branches[new_super_id]--
        status.missing_supers.add(super_id)
      }
    }
    else{
      status.tree[id] = { $: { _: {} } }
      status.tree_pointers[id] = status.tree[id].$
    }
    return status
  }
  function init_module () {
    const {statedata, state_entries, newstatus, updated_local_status} = get_module_data(local_status.fallback_module)
    statedata.orphan && (local_status.orphan = true)
    //side effects
    if (status.fallback_check) {
      Object.assign(status.root_module, newstatus.root_module)
      Object.assign(status.overrides, newstatus.overrides)
      console.log('Main module: ', statedata.id, '\n', state_entries)
      updated_local_status && Object.assign(local_status, updated_local_status)
      // console.log('Local status: ', local_status.fallback_instance, statedata.api)
      const old_fallback = local_status.fallback_instance
      
      if(local_status.fallback_instance ? local_status.fallback_instance?.toString() === statedata.api?.toString() : false)
        local_status.fallback_instance = statedata.api
      else
        local_status.fallback_instance = (args, tools) => {
          return statedata.api(args, tools, [old_fallback])
        }
      const extra_fallbacks = Object.entries(old_fallback || {})
      extra_fallbacks.length && extra_fallbacks.forEach(([key, value]) => {
        local_status.fallback_instance[key] = (args, tools) => {
          console.log('Extra fallback: ', statedata.api[key] ? statedata.api[key] : old_fallback[key])
          return (statedata.api[key] ? statedata.api[key] : old_fallback[key])(args, tools, [value])
        }
      })
      db.append(['state'], state_entries)
      // add_source_code(statedata.inputs) // @TODO: remove side effect
    }
    [local_status.sub_modules, symbol2ID, ID2Symbol, address2ID, ID2Address] = symbolfy(statedata, local_status)
    Object.assign(status.s2i, symbol2ID)
    Object.assign(status.i2s, ID2Symbol)
    Object.assign(status.a2i, address2ID)
    Object.assign(status.i2a, ID2Address)
    
    //Setup local data (module level)
    if(status.root_module){
      status.root_module = false
      statedata.admins && admins.push(...statedata.admins)
    }
    // @TODO: handle sub_modules when dynamic require is implemented
    // const sub_modules = {}
    // statedata.subs && statedata.subs.forEach(id => {
    //   sub_modules[db.read(['state', id]).type] = id
    // })
  }
  function init_instance (sid, fallback_key) {
    const fallback = local_status.fallback_instance[fallback_key] || local_status.fallback_instance
    const {statedata, state_entries, newstatus} = get_instance_data(sid, fallback)
    
    if (status.fallback_check) {
      Object.assign(status.root_module, newstatus.root_module)
      Object.assign(status.overrides, newstatus.overrides)
      Object.assign(status.tree, newstatus.tree)
      console.log('Main instance: ', statedata.id, '\n', state_entries)
      db.append(['state'], state_entries)
    }
    [local_status.sub_instances[statedata.id], symbol2ID, ID2Symbol, address2ID, ID2Address] = symbolfy(statedata, local_status)
    Object.assign(status.s2i, symbol2ID)
    Object.assign(status.i2s, ID2Symbol)
    Object.assign(status.a2i, address2ID)
    Object.assign(status.i2a, ID2Address)
    
    const sdb = create_statedb_interface(local_status, statedata.id, xtype = 'instance')
    sdb.id = statedata.id

    const sanitized_event = {}
    statedata.net && Object.keys(statedata.net).forEach(node => {
      statedata.net[node].id = status.a2i[node] || (status.a2i[node] = encode(node))
    })
    return {
      id: statedata.id,
      net: statedata.net,
      sdb: sdb.public_api,
      io: io(status.a2i[statedata.id], modulepath)
    }
  }
  function get_module_data (fallback) {
    let data = db.read(['state', modulepath])
    if (status.fallback_check) {
      if (data) {
        var {sanitized_data, updated_status} = validate_and_preprocess({ fun_status: status, fallback, xtype: 'module', pre_data: data })
      } 
      else if (status.root_module) {
        var {sanitized_data, updated_status} = validate_and_preprocess({ fun_status: status, fallback, xtype: 'module', pre_data: {id: modulepath}})
      } 
      else {
        var {sanitized_data, updated_status, updated_local_status} = find_super({ xtype: 'module', fallback, fun_status:status, local_status })
      }
      data = sanitized_data.entry
    }
    return {
      statedata: data,
      state_entries: sanitized_data?.entries,
      newstatus: updated_status,
      updated_local_status
    }
  }
  function get_instance_data (sid, fallback) {
    let id = status.s2i[sid]
    if(id && (id.split(':')[0] !== modulepath || !id.includes(':')))
        throw new Error(`Access denied! Wrong SID '${id}' used by instance of '${modulepath}'` + FALLBACK_SUBS_POST_ERROR)
    if(status.used_ids.has(id))
      throw new Error(`Access denied! SID '${id}' is already used` + FALLBACK_SUBS_POST_ERROR)

    id && status.used_ids.add(id)
    let data = id && db.read(['state', id])
    let sanitized_data, updated_status = status
    if (status.fallback_check) {
      if (!data && !status.root_instance) {
        ({sanitized_data, updated_status} = find_super({ xtype: 'instance', fallback, fun_status: status }))
      } else {
        ({sanitized_data, updated_status} = validate_and_preprocess({
          fun_status: status,
          fallback, 
          xtype: 'instance',
          pre_data: data || {id: get_instance_path(modulepath)}
        }))
        updated_status.root_instance = false
      }
      data = sanitized_data.entry
    }
    else if (status.root_instance) {
      data = db.read(['state', id || get_instance_path(modulepath)])
      updated_status.tree = JSON.parse(JSON.stringify(status.tree))
      updated_status.root_instance = false
    }
    
    if (!data && local_status.orphan) {
      data = db.read(['state', get_instance_path(modulepath)])
    }
    return {
      statedata: data,
      state_entries: sanitized_data?.entries,
      newstatus: updated_status,
    }
  }
  function find_super ({ xtype, fallback, fun_status, local_status }) {
    let modulepath_super = modulepath.split(/\>(?=[^>]*$)/)[0]
    let modulepath_grand = modulepath_super.split(/\>(?=[^>]*$)/)[0]
    if(status.modulepaths[modulepath_super] !== undefined){
      throw new Error(`Node "${modulepath}" is not defined in the fallback of "${modulepath_super}"` + FALLBACK_SUBS_POST_ERROR)
    }
    const split = modulepath.split('>')
    let data
    const entries = {}
    if(xtype === 'module'){
      let name = split.at(-1)
      while(!data && modulepath_grand.includes('>')){
        data = db.read(['state', modulepath_super])
        const split = modulepath_super.split(/\>(?=[^>]*$)/)
        modulepath_super = split[0]
        name = split[1] + '>' + name
      }
      console.log(data)
      data.path = data.id = modulepath_super + '>' + name
      modulepath = modulepath_super + '>' + name
      local_status.name = name

      const super_data = db.read(['state', modulepath_super])
      super_data.subs.forEach((sub_id, i) => {
        if(sub_id === modulepath_super){
          super_data.subs.splice(i, 1)
          return
        }
      })
      super_data.subs.push(data.id)
      entries[super_data.id] = super_data
    }
    else{
      //@TODO: Make the :0 dynamic
      let instance_path_super = modulepath_super + ':0'
      let temp
      while(!data && temp !== modulepath_super){
        data = db.read(['state', instance_path_super])
        temp = modulepath_super
        modulepath_grand = modulepath_super = modulepath_super.split(/\>(?=[^>]*$)/)[0]
        instance_path_super = modulepath_super + ':0'
      }
      data.path = data.id = get_instance_path(modulepath)
      temp = null
      let super_data
      let instance_path_grand = modulepath_grand.includes('>') ? modulepath_grand + ':0' : modulepath_grand

      while(!super_data?.subs && temp !== modulepath_grand){
        super_data = db.read(['state', instance_path_grand])
        temp = modulepath_grand
        modulepath_grand = modulepath_grand.split(/\>(?=[^>]*$)/)[0]
        instance_path_grand = modulepath_grand.includes('>') ? modulepath_grand + ':0' : modulepath_grand
      }
      
      super_data.subs.forEach((sub_id, i) => {
        if(sub_id === instance_path_super){
          super_data.subs.splice(i, 1)
          return
        }
      })
      super_data.subs.push(data.id)
      entries[super_data.id] = super_data
    }
    data.name = split.at(-1)
    return { updated_local_status: local_status,
      ...validate_and_preprocess({ 
      fun_status,
      fallback, xtype, 
      pre_data: data, 
      orphan_check: true, entries }) }
  }
  function validate_and_preprocess ({ fallback, xtype, pre_data = {}, orphan_check, fun_status, entries }) {
    const used_keys = new Set()
    let {id: pre_id, hubs: pre_hubs, mapping} = pre_data
    let fallback_data
    try {
      validate(fallback(status.args[pre_id], { listify: tree => listify(tree, modulepath), tree: status.tree_pointers[modulepath] }), xtype)
    } catch (error) {
      throw new Error(`in fallback function of ${pre_id} ${xtype}\n${error.stack}`)
    }
    if(fun_status.overrides[pre_id]){
      fallback_data = fun_status.overrides[pre_id].fun[0](status.args[pre_id], { listify: tree => listify(tree, modulepath), tree: status.tree_pointers[modulepath] }, get_fallbacks({ fallback, modulename: local_status.name, modulepath, instance_path: pre_id }))
      console.log('Override used: ', pre_id)
      fun_status.overrides[pre_id].by.splice(0, 1)
      fun_status.overrides[pre_id].fun.splice(0, 1)
    }
    else
      fallback_data = fallback(status.args[pre_id], { listify: tree => listify(tree, modulepath), tree: status.tree_pointers[modulepath] })

    // console.log('fallback_data: ', fallback)
    fun_status.overrides = register_overrides({ overrides: fun_status.overrides, tree: fallback_data, path: modulepath, id: pre_id })
    console.log('overrides: ', Object.keys(fun_status.overrides))
    orphan_check && (fallback_data.orphan = orphan_check)
    //This function makes changes in fun_status (side effect)
    return {
      sanitized_data: sanitize_state({ local_id: '', entry: fallback_data, path: pre_id, xtype, mapping, entries }),
      updated_status: fun_status
    }
    
    function sanitize_state ({ local_id, entry, path, hub_entry, local_tree, entries = {}, xtype, mapping, xkey }) {
      [path, entry, local_tree] = extract_data({ local_id, entry, path, hub_entry, local_tree, xtype, xkey })

      entry.id =  path
      entry.name = entry.name || local_id.split(':')[0] || local_status.name
      mapping && (entry.mapping = mapping)
      
      entries = {...entries, ...sanitize_subs({ local_id, entry, path, local_tree, xtype, mapping })}
      delete entry._
      entries[entry.id] = entry
      // console.log('Entry: ', entry)
      return {entries, entry}
    }
    function extract_data ({ local_id, entry, path, hub_entry, xtype, xkey }) {
      if (local_id) {
        entry.hubs = [hub_entry.id]
        if (xtype === 'instance') {
          let temp_path = path.split(':')[0]
          temp_path = temp_path ? temp_path + '>' : temp_path
          const module_id = temp_path + local_id
          entry.type = module_id
          path = module_id + ':' + xkey
          temp = Number(xkey)+1
          temp2 = db.read(['state', path])
          while(temp2 || used_keys.has(path)){
            path = module_id + ':' + temp
            temp2 = db.read(['state', path])
            temp++
          }
        }
        else {
          entry.type = local_id
          path = path ? path + '>' : ''
          path = path + local_id
        }
      } 
      else {
        if (xtype === 'instance') {
          entry.type = local_status.module_id
        } else {
          local_tree = JSON.parse(JSON.stringify(entry))
          // @TODO Handle JS file entry
          // console.log('pre_id:', pre_id)
          // const file_id = local_status.name + '.js'
          // entry.drive || (entry.drive = {})
          // entry.drive[file_id] = { $ref: address }
          entry.type = local_status.name
        }
        pre_hubs && (entry.hubs = pre_hubs)
      }
      return [path, entry, local_tree]
    }
    function sanitize_subs ({ local_id, entry, path, local_tree, xtype, mapping }) {
      const entries = {}
      if (!local_id) {
        entry.subs = []
        if(entry._){
          //@TODO refactor when fallback structure improves
          Object.entries(entry._).forEach(([local_id, value]) => {
            Object.entries(value).forEach(([key, override]) => {
              if(key === 'mapping' || (key === '$' && xtype === 'instance'))
                return
              const sub_instance = sanitize_state({ local_id, entry: value, path, hub_entry: entry, local_tree, xtype: key === '$' ? 'module' : 'instance', mapping: value['mapping'], xkey: key }).entry
              entries[sub_instance.id] = JSON.parse(JSON.stringify(sub_instance))
              entry.subs.push(sub_instance.id)
              used_keys.add(sub_instance.id)
            })
        })}
        if (entry.drive) {
          // entry.drive.theme && (entry.theme = entry.drive.theme)
          // entry.drive.lang && (entry.lang = entry.drive.lang)
          entry.inputs = []
          const new_drive = []
          Object.entries(entry.drive).forEach(([dataset_type, dataset]) => {
            dataset_type = dataset_type.split('/')[0]

            const new_dataset = { files: [], mapping: {} }
            Object.entries(dataset).forEach(([key, value]) => {
              const sanitized_file = sanitize_file(key, value, entry, entries)
              entries[sanitized_file.id] = sanitized_file
              new_dataset.files.push(sanitized_file.id)
            })
            new_dataset.id = entry.id + '.' + dataset_type + '.dataset'
            new_dataset.type = dataset_type
            new_dataset.name = 'default'
            const copies = Object.keys(db.read_all(['state', new_dataset.id]))
            if (copies.length) {
              const id = copies.sort().at(-1).split(':')[1]
              new_dataset.id = new_dataset.id + ':' + (Number(id || 0) + 1)
            }
            entries[new_dataset.id] = new_dataset
            let check_name = true
            entry.inputs.forEach(dataset_id => {
              const ds = entries[dataset_id]
              if(ds.type === new_dataset.type)
                check_name = false
            })
            check_name && entry.inputs.push(new_dataset.id)
            new_drive.push(new_dataset.id)


            if(!status.root_module){
              const hub_entry = db.read(['state', entry.hubs[0]])
              console.log(hub_entry, entry)
              if(!hub_entry.inputs)
                throw new Error(`Node "${hub_entry.id}" has no "drive" defined in its fallback` + FALLBACK_SUBS_POST_ERROR)
              if(!mapping?.[dataset_type])
                throw new Error(`No mapping found for dataset "${dataset_type}" of subnode "${entry.id}" in node "${hub_entry.id}"\nTip: Add a mapping prop for "${dataset_type}" dataset in "${hub_entry.id}"'s fallback for "${entry.id}"` + FALLBACK_POST_ERROR)
              const mapped_file_type = mapping[dataset_type]
              hub_entry.inputs.some(input_id => {
                const input = db.read(['state', input_id])
                if(mapped_file_type === input.type){
                  input.mapping[entry.id] = new_dataset.id
                  entries[input_id] = input
                  return
                }
              })
            }
          })
          entry.drive = new_drive
        }
      }
      return entries
    }
    function sanitize_file (file_id, file, entry, entries) {
      const type = file_id.split('.').at(-1)

      if (!isNaN(Number(file_id))) return file_id

      const raw_id = local_status.name + '.' + type
      file.id = raw_id
      file.name = file.name || file_id
      file.type = type
      file[file.type === 'js' ? 'subs' : 'hubs'] = [entry.id]
      if(file.$ref){
        file.$ref = address.substring(0, address.lastIndexOf("/")) + '/' + file.$ref
      }
      const copies = Object.keys(db.read_all(['state', file.id]))
      if (copies.length) {
        const no = copies.sort().at(-1).split(':')[1]
        file.id = raw_id + ':' + (Number(no || 0) + 1)
      }
      while(entries[file.id]){
        const no = file.id.split(':')[1]
        file.id = raw_id + ':' + (Number(no || 0) + 1)
      }
      return file
    }
  }
}

// External Function (helper)
function validate (data, xtype) {
  /**  Expected structure and types
   * Sample : "key1|key2:*:type1|type2"
   * ":" : separator
   * "|" : OR
   * "*" : Required key
   * */
  const expected_structure = {
    'api::function': () => {},
    '_::object': {
      ":*:object|number": {
        ":*:function|string|object": '',
        "mapping::": {}
      }
    },
    'drive::object': {
      "::object": {
        "::object": { // Required key, any name allowed
          "raw|$ref:*:object|string": {}, // data or $ref are names, required, object or string are types
          "$ref": "string"
        }
      },
    },
    'net::object': {}
  }

  validate_shape(data, expected_structure)

  function validate_shape (obj, expected, super_node = 'root', path = '') {
    const keys = Object.keys(obj)
    const values = Object.values(obj)
    let strict = Object.keys(expected).length

    const all_keys = []
    Object.entries(expected).forEach(([expected_key, expected_value]) => {
      let [expected_key_names, required, expected_types] = expected_key.split(':')
      expected_types = expected_types ? expected_types.split('|') : [typeof(expected_value)]
      let absent = true
      if(expected_key_names)
        expected_key_names.split('|').forEach(expected_key_name => {
          const value = obj[expected_key_name]
          if(value !== undefined){
            all_keys.push(expected_key_name)
            const type = typeof(value)
            absent = false

            if(expected_types.includes(type))
              type === 'object' && validate_shape(value, expected_value, expected_key_name, path + '/' + expected_key_name)
            else
              throw new Error(`Type mismatch: Expected "${expected_types.join(' or ')}" got "${type}" for key "${expected_key_name}" at:` + path + FALLBACK_POST_ERROR)
          }
        })
      else{
        strict = false
        values.forEach((value, index) => {
          absent = false
          const type = typeof(value)

          if(expected_types.includes(type))
            type === 'object' && validate_shape(value, expected_value, keys[index], path + '/' + keys[index])
          else
            throw new Error(`Type mismatch: Expected "${expected_types.join(' or ')}" got "${type}" for key "${keys[index]}" at: ` + path + FALLBACK_POST_ERROR)
        })
      }
      if(absent && required){
        if(expected_key_names)
          throw new Error(`Can't find required key "${expected_key_names.replace('|', ' or ')}" at: ` + path + FALLBACK_POST_ERROR)
        else
          throw new Error(`No sub-nodes found for super key "${super_node}" at sub: ` + path + FALLBACK_POST_ERROR)
      }
    })

    strict && keys.forEach(key => {
      if(!all_keys.includes(key)){
        throw new Error(`Unknown key detected: '${key}' is an unknown property at: ${path || 'root'}` + FALLBACK_POST_ERROR)
      }
    })
  }
}
function extract_filename (address) {
  const parts = address.split('/node_modules/')
  const last = parts.at(-1).split('/')
  if(last.at(-1) === 'index.js')
    return last.at(-2)
  return last.at(-1).slice(0, -3)
}
function get_instance_path (modulepath, modulepaths = status.modulepaths) {
  return modulepath + ':' + modulepaths[modulepath]++
}
async function get_input ({ id, name, $ref, type, raw }) {
  const xtype = (typeof(id) === "number" ? name : id).split('.').at(-1)
  let result = db.read([type, id])
  
  if (!result) {
    if (raw === undefined){
      let ref_url = $ref
      // Patch: Prepend GitHub project name if running on GitHub Pages
      if (typeof window !== 'undefined' && window.location.hostname.endsWith('github.io')) {
        const path_parts = window.location.pathname.split('/').filter(Boolean)
        if (path_parts.length > 0 && !$ref.startsWith('/' + path_parts[0])) {
          ref_url = '/' + path_parts[0] + ($ref.startsWith('/') ? '' : '/') + $ref
        }
      }
      const response = await fetch(ref_url)
      if (!response.ok) 
        throw new Error(`Failed to fetch data from '${ref_url}' for '${id}'` + FALLBACK_SYNTAX_POST_ERROR)
      else
        result = await response[xtype === 'json' ? 'json' : 'text']()
    }
    else
      result = raw
  }
  return result
}
//Unavoidable side effect
function add_source_code (hubs) {
  hubs.forEach(async id => {
    const data = db.read(['state', id])
    if (data.type === 'js') {
      data.data = await get_input(data)
      db.add(['state', data.id], data)
      return
    }
  })
}
function verify_imports (id, imports, data) {
  const state_address = imports.find(imp => imp.includes('STATE'))
  HELPER_MODULES.push(state_address)
  imports = imports.filter(imp => !HELPER_MODULES.includes(imp))
  if(!data._){
    if(imports.length > 1){
      imports.splice(imports.indexOf(state_address), 1)
      throw new Error(`No sub-nodes found for required modules "${imports.join(', ')}" in the fallback of "${status.local_statuses[id].module_id}"` + FALLBACK_POST_ERROR)
    }
    else return
  }
  const fallback_imports = Object.keys(data._)

  imports.forEach(imp => {
    let check = true
    fallback_imports.forEach(fallimp => {
      if(imp === fallimp)
        check = false
    })

    if(check)
      throw new Error('Required module "'+imp+'" is not defined in the fallback of '+status.local_statuses[id].module_id + FALLBACK_POST_ERROR)
  })
  
  fallback_imports.forEach(fallimp => {
    let check = true
    imports.forEach(imp => {
      if(imp === fallimp)
        check = false
    })
    
    if(check)
      throw new Error('Module "'+fallimp+'" defined in the fallback of '+status.local_statuses[id].module_id+' is not required')
  })

}
function symbolfy (data) {
  const i2s = {}
  const s2i = {}
  const i2a = {}
  const a2i = {}
  const subs = []
  data.subs && data.subs.forEach(sub => {
    const substate = db.read(['state', sub])
    i2a[a2i[sub] = encode(sub)] = sub
    s2i[i2s[sub] = Symbol(a2i[sub])] = sub
    subs.push({ sid: i2s[sub], type: substate.type })
  })
  return [subs, s2i, i2s, a2i, i2a]
}
function encode(text) {
  let code = ''
  while (code.length < 10) {
    for (let i = 0; i < text.length && code.length < 10; i++) {
      code += Math.floor(10 + Math.random() * 90)
    }
  }
  return code
}
function listify(tree, prefix = '') {
  if (!tree)
    return []
  
  const result = []

  function walk(current, prefix = '') {
    for (const key in current) {
      if (key === '$' && current[key]._ && typeof current[key]._ === 'object') {
        walk(current[key]._, prefix)
      } else {
        const path = prefix ? `${prefix}>${key}` : key
        result.push(path)
        if (current[key]?.$?._ && typeof current[key].$._ === 'object') {
          walk(current[key].$._, path)
        }
      }
    }
  }

  if (tree._ && typeof tree._ === 'object') {
    walk(tree._, prefix)
  }

  return result
}
function register_overrides ({overrides, ...args}) {
  recurse(args)
  return overrides
  function recurse ({ tree, path = '', id, xtype = 'instance', local_modulepaths = {} }) {

    tree._ && Object.entries(tree._).forEach(([type, instances]) => {
      const sub_path = path + '>' + type
      Object.entries(instances).forEach(([id, override]) => {
        const resultant_path = id === '$' ? sub_path : sub_path + ':' + id
        if(typeof(override) === 'function'){
          if(overrides[resultant_path]){
            overrides[resultant_path].fun.push(override)
            overrides[resultant_path].by.push(id)
          }
          else
            overrides[resultant_path] = {fun: [override], by: [id]}
        }
        else if ( ['object', 'string'].includes(typeof(override)) && id !== 'mapping' && override._ === undefined)
          status.args[resultant_path] = structuredClone(override)
        else
          recurse({ tree: override, path: sub_path, id, xtype, local_modulepaths })
      })
    })
  }
}
function get_fallbacks ({ fallback, modulename, modulepath, instance_path }) {
  return [mutated_fallback, ...status.overrides[instance_path].fun]
    
  function mutated_fallback () {
    const data = fallback(status.args[instance_path], { listify: tree => listify(tree, modulepath), tree: status.tree_pointers[modulepath] })

    data.overrider = status.overrides[instance_path].by[0]
    merge_trees(data, modulepath)
    return data

    function merge_trees (data, path) {
      if (data._) {
        Object.entries(data._).forEach(([type, data]) => merge_trees(data, path + '>' + type.split('$')[0].replace('.', '>')))
      } else {
        data.$ = { _: status.tree_pointers[path]?._ }
      }
    }
  }
}
function check_version () {
  if (db.read(['playproject_version']) != VERSION) {
    localStorage.clear()
    return true
  }
}

// Public Function
function create_statedb_interface (local_status, node_id, xtype) {
  const drive = {
        get, has, put, list
      }
  const api =  {
    public_api: {
      watch, get_sub, drive
    },
    private_api: {
      drive,
      xget: (id) => db.read(['state', id]),
      get_all: () => db.read_all(['state']),
      get_db,
      register,
      load: (snapshot) => {
        localStorage.clear()
        Object.entries(snapshot).forEach(([key, value]) => {
          db.add([key], JSON.parse(value), true)
        })
        window.location.reload()
      },
      swtch,
      unregister,
      status,
    }
  }
  node_id === status.ROOT_ID && (api.public_api.admin = api.private_api)
  return api

  async function watch (listener, on) {
    if(on)
      status.services[node_id] = Object.keys(on)
    const data = db.read(['state', node_id])
    if(listener){
      status.listeners[data.id] = listener
      await listener(await make_input_map(data.inputs))
    }
    return xtype === 'module' ? local_status.sub_modules : local_status.sub_instances[node_id]
  }
  function get_sub (type) {
    const subs = xtype === 'module' ? local_status.sub_modules : local_status.sub_instances[node_id]
    return subs.filter(sub => sub.type === type)
  }
  function get_db ({ type: dataset_type, name: dataset_name } = {}) {
    const node = db.read(['state', status.ROOT_ID])
    if(dataset_type){
      const dataset_list = []
      node.drive.forEach(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if(dataset.type === dataset_type)
          dataset_list.push(dataset.name)
      })
      if(dataset_name){
        return recurse(status.ROOT_ID, dataset_type)
      }
      return dataset_list
    }
    const datasets = []
    node.inputs && node.inputs.forEach(dataset_id => {
      datasets.push(db.read(['state', dataset_id]).type)
    })
    return datasets
  
    function recurse (node_id, dataset_type){
      const node_list = []
      const entry = db.read(['state', node_id])
      const temp = entry.mapping ? Object.keys(entry.mapping).find(key => entry.mapping[key] === dataset_type) : null
      const mapped_type = temp || dataset_type
      entry.drive && entry.drive.forEach(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if(dataset.name === dataset_name && dataset.type === mapped_type){
          node_list.push(node_id)
          return
        }
      })
      entry.subs && entry.subs.forEach(sub_id => node_list.push(...recurse(sub_id, mapped_type)))
      return node_list
    }
  }
  function register ({ type: dataset_type, name: dataset_name, dataset}) {
    Object.entries(dataset).forEach(([node_id, files]) => {
      const new_dataset = { files: [] }
      Object.entries(files).forEach(([file_id, file]) => {
        const type = file_id.split('.').at(-1)
        
        file.id = local_status.name + '.' + type
        file.local_name = file_id
        file.type = type
        file[file.type === 'js' ? 'subs' : 'hubs'] = [node_id]
        
        const copies = Object.keys(db.read_all(['state', file.id]))
        if (copies.length) {
          const no = copies.sort().at(-1).split(':')[1]
          file.id = file.id + ':' + (Number(no || 0) + 1)
        }  
        db.add(['state', file.id], file)
        new_dataset.files.push(file.id)
      })
  
      const node = db.read(['state', node_id])
      new_dataset.id = node.name + '.' + dataset_type + '.dataset'
      new_dataset.name = dataset_name
      new_dataset.type = dataset_type
      const copies = Object.keys(db.read_all(['state', new_dataset.id]))
      if (copies.length) {
        const id = copies.sort().at(-1).split(':')[1]
        new_dataset.id = new_dataset.id + ':' + (Number(id || 0) + 1)
      }
      db.push(['state', node_id, 'drive'], new_dataset.id)
      db.add(['state', new_dataset.id], new_dataset)
    })
    console.log(' registered ' + dataset_name + '.' + dataset_type)
  }
  function unregister ({ type: dataset_type, name: dataset_name } = {}) {
    return recurse(status.ROOT_ID)

    function recurse (node_id){
      const node = db.read(['state', node_id])
      node.drive && node.drive.some(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if(dataset.name === dataset_name && dataset.type === dataset_type){
          node.drive.splice(node.drive.indexOf(dataset_id), 1)
          return true
        }
      })
      node.inputs && node.inputs.some(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if(dataset.name === dataset_name && dataset.type === dataset_type){
          node.inputs.splice(node.inputs.indexOf(dataset_id), 1)
          swtch(dataset_type)
          return true
        }
      })
      db.add(['state', node_id], node)
      node.subs.forEach(sub_id => recurse(sub_id))
    }
  }
  function swtch ({ type: dataset_type, name: dataset_name = 'default'}) {
    recurse(dataset_type, dataset_name, status.ROOT_ID)

    async function recurse (target_type, target_name, id) {
      const node = db.read(['state', id])
      
      let target_dataset
      node.drive && node.drive.forEach(dataset_id => {
        const dataset = db.read(['state', dataset_id])
        if(target_name === dataset.name && target_type === dataset.type){
          target_dataset = dataset
          return
        }
      })
      if(target_dataset){
        node.inputs.forEach((dataset_id, i) => {
          const dataset = db.read(['state', dataset_id])
          if(target_type === dataset.type){
            node.inputs.splice(i, 1)
            return
          }
        })
        node.inputs.push(target_dataset.id)
      }
      db.add(['state', id], node)
      status.listeners[id] && status.listeners[id](await make_input_map(node.inputs))
      node.subs && node.subs.forEach(sub_id => {
        const subdataset_id = target_dataset?.mapping?.[sub_id] 
        recurse(target_type, db.read(['state', subdataset_id])?.name || target_name, sub_id)
      })
    }
  }
  
  function list (path, id = node_id) {
    const node = db.read(['state', id])
    if(!node.drive)
      throw new Error(`Node "${id}" has no drive`)
    const dataset_names = node.drive.map(dataset_id => {
      return dataset_id.split('.').at(-2) + '/'
    })
    
    if (path) {
      let index
      dataset_names.some((dataset_name, i) => {
        if (path.includes(dataset_name)) {
          index = i
          return true
        }
      })
      if (index === undefined)
        throw new Error(`Dataset "${path}" not found in node "${node.name}"`) 
      const dataset = db.read(['state', node.drive[index]])
      return dataset.files.map(fileId => {
        const file = db.read(['state', fileId])
        return file.name
      })
    }
    return dataset_names
  }
  async function get (path, id = node_id) {
    const [dataset_name, file_name] = path.split('/')
    const node = db.read(['state', id])
    let dataset
    if(!node.drive)
      throw new Error(`Node ${node.id} has no drive defined in its fallback` + FALLBACK_POST_ERROR)
    node.drive.some(dataset_id => {
      if (dataset_name === dataset_id.split('.').at(-2)) {
        dataset = db.read(['state', dataset_id])
        return true
      }
    })
    if (!dataset) 
      throw new Error(`Dataset "${dataset_name}" not found in node "${node.name}"`)
    
    let target_file
    for (const file_id of dataset.files) {
      const file = db.read(['state', file_id])
      if (file.name === file_name) {
        target_file =  { id: file.id, name: file.name, type: file.type, raw: await get_input(file)}
        break
      }
    }
    if (!target_file)
      throw new Error(`File "${path}" not found`)
    return target_file
  }
  async function put (path, buffer, id = node_id) {
    const [dataset_name, filename] = path.split('/')
    let dataset
    const node = db.read(['state', id])
    node.drive.some(dataset_id => {
      if (dataset_name === dataset_id.split('.').at(-2)) {
        dataset = db.read(['state', dataset_id])
        return true
      }
    })
    if (!dataset) 
      throw new Error(`Dataset "${dataset_name}" not found in node "${node.name}"`)
    const type = filename.split('.').pop()
    const raw_id = node.name + '.' + type
    const file = {
      id: raw_id,
      name: filename,
      type,
      raw: buffer
    }
    for (const file_id of dataset.files) {
      const temp_file = db.read(['state', file_id])
      if(file.name === filename){
        file.id = file_id
        break
      }
    }
    if(!dataset.files.includes(file.id)){
      const copies = Object.keys(db.read_all(['state', file.id]))
      if (copies.length) {
        const no = copies.sort().at(-1).split(':')[1]
        file.id = raw_id + ':' + (Number(no || 0) + 1)
      }
      dataset.files.push(file.id)
      db.add(['state', dataset.id], dataset)
    }
    db.add(['state', file.id], file)
    await status.listeners[node.id](await make_input_map(node.inputs))

    return { id: file.id, name: filename, type, raw: buffer }
  }
  function has (path) {
    const [dataset_name, filename] = path.split('/')
    let dataset
    const node = db.read(['state', node_id])
    node.drive.some(dataset_id => {
      if (dataset_name === dataset_id.split('.').at(-2)) {
        dataset = db.read(['state', dataset_id])
        return true
      }
    })
    if (!dataset) 
      throw new Error(`Dataset "${dataset_name}" not found in node "${node.name}"`)
    return dataset.files.some(file_id => {
      const file = db.read(['state', file_id])
      return file && file.name === filename
    })
  }
}
async function make_input_map (inputs) {
  const input_map = []   
  if (inputs) {
    await Promise.all(inputs.map(async input => {
      let files = []
      const dataset = db.read(['state', input])
      await Promise.all(dataset.files.map(async file_id => {
        const input_state = db.read(['state', file_id])
        files.push(dataset.id.split('.').at(-2) + '/' + input_state.name)
      }))
      input_map.push({ type: dataset.type, paths: files })
    }))
  }
  return input_map
}


module.exports = STATE